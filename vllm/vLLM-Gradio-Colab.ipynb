{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 148595,
     "status": "ok",
     "timestamp": 1741161610128,
     "user": {
      "displayName": "Tùng Dương Trần",
      "userId": "11628672730776691023"
     },
     "user_tz": -420
    },
    "id": "t-Pgz-QkhII4",
    "outputId": "2e779c50-ce9f-445e-dd38-3e46df156fff"
   },
   "outputs": [],
   "source": [
    "!pip install -q vllm gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 6405,
     "status": "ok",
     "timestamp": 1741162537891,
     "user": {
      "displayName": "Tùng Dương Trần",
      "userId": "11628672730776691023"
     },
     "user_tz": -420
    },
    "id": "dzxrSjvE_8cQ",
    "outputId": "0faef6c3-19b9-4c91-cb05-6f5831bee46b"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "\n",
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:8000/v1/chat/completions\"\n",
    "MODEL_NAME = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "\n",
    "\n",
    "async def chat_with_llm(message, history):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    if history:\n",
    "        for user_msg, bot_reply in history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "    # Append the latest user message\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stream\": True,\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload), \"stream\": Truez)\n",
    "    bot_message = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                data = line.decode(\"utf-8\").replace(\"data: \", \"\").strip()\n",
    "                if data == \"[DONE]\":\n",
    "                    break\n",
    "                chunk = json.loads(data)[\"choices\"][0][\"delta\"][\"content\"]\n",
    "                bot_message += chunk\n",
    "                yield bot_message  # Stream partial response\n",
    "                await asyncio.sleep(0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing response chunk: {e}\")\n",
    "                \n",
    "\n",
    "# Launch Gradio chat interface\n",
    "gr.ChatInterface(fn=chat_with_llm, title=\"vLLM Chatbot\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 503408,
     "status": "ok",
     "timestamp": 1741163055509,
     "user": {
      "displayName": "Tùng Dương Trần",
      "userId": "11628672730776691023"
     },
     "user_tz": -420
    },
    "id": "5D2oJREeCry3",
    "outputId": "c4ed573c-bb5b-425d-97b2-6e512e541efd"
   },
   "outputs": [],
   "source": [
    "!python -m vllm.entrypoints.openai.api_server \\\n",
    "--model Qwen/Qwen2-1.5B-Instruct \\\n",
    "--trust-remote-code \\\n",
    "--dtype half"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM8LO6I6hL1We+YRr/pR+/G",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
